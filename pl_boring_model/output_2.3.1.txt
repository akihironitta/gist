GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
/home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
/home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
W0710 18:36:15.968000 140004033020544 torch/_logging/_internal.py:1034] [1/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
V0710 18:36:18.651000 140004033020544 torch/_dynamo/guards.py:2611] [4/1] [__recompiles] Recompiling function _call_strategy_hook in /home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:294
V0710 18:36:18.651000 140004033020544 torch/_dynamo/guards.py:2611] [4/1] [__recompiles]     triggered by the following guard failure(s):
V0710 18:36:18.651000 140004033020544 torch/_dynamo/guards.py:2611] [4/1] [__recompiles]     - L['hook_name'] == 'training_step'
V0710 18:36:18.658000 140004033020544 torch/_dynamo/guards.py:2611] [5/1] [__recompiles] Recompiling function torch_dynamo_resume_in__call_strategy_hook_at_300 in /home/aki/miniconda3/envs/oss310/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:300
V0710 18:36:18.658000 140004033020544 torch/_dynamo/guards.py:2611] [5/1] [__recompiles]     triggered by the following guard failure(s):
V0710 18:36:18.658000 140004033020544 torch/_dynamo/guards.py:2611] [5/1] [__recompiles]     - L['hook_name'] == 'training_step'
`Trainer.fit` stopped: `max_epochs=5` reached.
